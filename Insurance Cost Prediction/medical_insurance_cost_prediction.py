# -*- coding: utf-8 -*-
"""Medical insurance cost prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ox1DCyPXoJuoVIh3Zj9VyMuuwUb2C907

#Medical Insurance Cost Prediction
##Traditional Regression Vs Quantile Regression

Here, We will explore a dataset consists of patients data for medical cost. The cost of medical treatment depends on many factors: number of diseases, diseases, bmi, , diagbosis, number of childeren, city of residence, age and so on. We have data which can help us to find patterns or draw conclusion about health of patients and their medical costs. But we dont have personal data like diseases and diagnosis.
Let's jump into data and explore it.

### Importing necessary libraries
"""

#!pip install deap

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import xgboost as xgb

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_selection import RFECV
from sklearn.linear_model import LinearRegression
#from deap import base, creator, tools, algorithms
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from scipy.stats import norm
import matplotlib as mpl
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge, Lasso, LinearRegression

"""Importing Data"""

# Load the dataset
file_path = 'https://raw.githubusercontent.com/shubhamvm/Kaggle/main/Final%20Project/Datasets/insurance.csv'
data = pd.read_csv(file_path)
data.head()

# Check for missing values
missing_values = data.isnull().sum()
print("Missing Values in Each Column:")
print(missing_values)

# Check data types
data_types = data.dtypes
print("\nData Types of Each Column:")
print(data_types)

# Summary statistics for all columns
summary_stats = data.describe(include='all')
print("\nSummary Statistics:")
print(summary_stats)

# Define the numerical features
numerical_cols = ['charges', 'age', 'bmi', 'children']

# Set up the figure and axes
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))
axes = axes.flatten()

# Plot the distributions
for i, col in enumerate(numerical_cols):
    sns.histplot(data=data, x=col, bins=30, kde=True, ax=axes[i])
    axes[i].set_title(f'Distribution of {col}', fontweight='bold')
    axes[i].set_xlabel(col, fontweight='semibold')
    axes[i].set_ylabel('Frequency', fontweight='semibold')

# Adjust spacing between subplots
plt.subplots_adjust(hspace=0.5, wspace=0.3)

# Display the plot
plt.show()

# Define the numerical and categorical features
numerical_cols = ['age', 'bmi', 'children']
categorical_cols = ['sex', 'smoker', 'region']

# Set up the figure and axes
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))
axes = axes.flatten()

# Scatter plots for numerical variables vs. charges
for i, col in enumerate(numerical_cols):
    if col != 'charges':
        sns.scatterplot(x=data[col], y=data['charges'], ax=axes[i])
        axes[i].set_title(f'{col} vs Charges', fontweight='bold')
        axes[i].set_xlabel(col, fontweight='semibold')
        axes[i].set_ylabel('Charges', fontweight='semibold')

# Box plots for categorical variables vs. charges
for i, col in enumerate(categorical_cols, start=len(numerical_cols)):
    sns.boxplot(x=data[col], y=data['charges'], ax=axes[i])
    axes[i].set_title(f'{col} vs Charges', fontweight='bold')
    axes[i].set_xlabel(col, fontweight='semibold')
    axes[i].set_ylabel('Charges', fontweight='semibold')

# Adjust spacing between subplots
plt.subplots_adjust(hspace=0.5, wspace=0.3)

# Display the plot
plt.show()

# Convert categorical variables to numerical codes
data_numeric = data.copy()
data_numeric['sex'] = data_numeric['sex'].astype('category').cat.codes
data_numeric['smoker'] = data_numeric['smoker'].astype('category').cat.codes
data_numeric['region'] = data_numeric['region'].astype('category').cat.codes

# Display the first few rows of the resulting dataframe
data_numeric.head()

"""region: northwest = 1, southeast = 2, southwest = 3, northeast = 4

sex: female = 0, male = 1

smoker: smoker = 1, non-smoker = 0
"""

# Compute the correlation matrix
correlation_matrix = data_numeric.corr()

# Display the correlation matrix
print(correlation_matrix)

# Plot the correlation matrix
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix', fontweight='bold')
plt.show()



# Define the numerical and categorical features
numerical_cols = ['age', 'bmi', 'children']
categorical_cols = ['sex', 'smoker', 'region']

# Take log of 'charges' column
data['log_charges'] = np.log(data['charges'])

# Set up the figure and axes
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))
axes = axes.flatten()

# Scatter plots for numerical variables vs. charges
for i, col in enumerate(numerical_cols):
    if col != 'charges':
        sns.scatterplot(x=data[col], y=data['log_charges'], ax=axes[i])
        axes[i].set_title(f'{col} vs Log(Charges)', fontweight='bold')
        axes[i].set_xlabel(col, fontweight='semibold')
        axes[i].set_ylabel('Log(Charges)', fontweight='semibold')

# Box plots for categorical variables vs. charges
for i, col in enumerate(categorical_cols, start=len(numerical_cols)):
    sns.boxplot(x=data[col], y=data['log_charges'], ax=axes[i])
    axes[i].set_title(f'{col} vs Log(Charges)', fontweight='bold')
    axes[i].set_xlabel(col, fontweight='semibold')
    axes[i].set_ylabel('Log(Charges)', fontweight='semibold')

# Adjust spacing between subplots
plt.subplots_adjust(hspace=0.5, wspace=0.3)

# Display the plot
plt.show()

# Define the numerical feature
numerical_col = 'charges'

# Plot the histogram and kernel density estimate
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x=numerical_col, kde=True, stat="density", bins=30, color="skyblue")

# Create a range of values for the x-axis
xmin, xmax = plt.xlim()
ymin, ymax = plt.ylim()
x = np.linspace(xmin, xmax, 100)

# Fit the data to a normal distribution
mean_value, std_dev = norm.fit(data[numerical_col])

# Plot the PDF using the normal distribution
pdf = norm.pdf(x, mean_value, std_dev)
plt.plot(x, pdf, 'k', linewidth=2)

# Plot mean and standard deviation lines
plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_value:.2f}')
plt.axvline(mean_value - std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Mean - Std Dev = {(mean_value - std_dev):.2f}')
plt.axvline(mean_value + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Mean + Std Dev = {(mean_value + std_dev):.2f}')

# Fill the area between mean - std_dev and mean + std_dev with color
x_fill = np.linspace(mean_value - std_dev, mean_value + std_dev, 100)
y_fill = np.exp(-(x_fill - mean_value)**2 / (2 * std_dev**2)) / (std_dev * np.sqrt(2 * np.pi))
plt.fill_between(x_fill, y_fill, color='red', alpha=0.3, label='Mean ± Std Dev Area')

# Add text annotations
plt.text(xmax * 0.6, ymax * 0.5, f'Mean Charges (W~): {mean_value:.2f}', fontsize=10, color='red')
plt.text(xmax * 0.6, ymax * 0.45, f'Standard Deviation (X): {std_dev:.2f}', fontsize=10, color='green')

# Set plot labels and title
plt.xlabel('Charges ($)', fontweight='bold')
plt.ylabel('Probability Density', fontweight='bold')
plt.title('Probability Density Function with Mean and Standard Deviation', fontweight='bold')

# Add legend
plt.legend()

# Display the plot
plt.show()

# Define the numerical feature
numerical_col = 'log_charges'

# Plot the histogram and kernel density estimate
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x=numerical_col, kde=True, stat="density", bins=30, color="skyblue")

# Create a range of values for the x-axis
xmin, xmax = plt.xlim()
ymin, ymax = plt.ylim()
x = np.linspace(xmin, xmax, 100)

# Fit the data to a normal distribution
mean_value, std_dev = norm.fit(data[numerical_col])

# Plot the PDF using the normal distribution
pdf = norm.pdf(x, mean_value, std_dev)
plt.plot(x, pdf, 'k', linewidth=2)

# Plot mean and standard deviation lines
plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_value:.2f}')
plt.axvline(mean_value - std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Mean - Std Dev = {(mean_value - std_dev):.2f}')
plt.axvline(mean_value + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Mean + Std Dev = {(mean_value + std_dev):.2f}')

# Fill the area between mean - std_dev and mean + std_dev with color
x_fill = np.linspace(mean_value - std_dev, mean_value + std_dev, 100)
y_fill = np.exp(-(x_fill - mean_value)**2 / (2 * std_dev**2)) / (std_dev * np.sqrt(2 * np.pi))
plt.fill_between(x_fill, y_fill, color='red', alpha=0.3, label='Mean ± Std Dev Area')

# Add text annotations
plt.text(xmax * 0.6, ymax * 0.5, f'Mean Charges (W~): {mean_value:.2f}', fontsize=10, color='red')
plt.text(xmax * 0.6, ymax * 0.45, f'Standard Deviation (X): {std_dev:.2f}', fontsize=10, color='green')

# Set plot labels and title
plt.xlabel('log_charges ($)', fontweight='bold')
plt.ylabel('Probability Density', fontweight='bold')
plt.title('Probability Density Function with Mean and Standard Deviation', fontweight='bold')

# Add legend
plt.legend()

# Display the plot
plt.show()

# Set up the figure and axes
fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))

# Violin plot for all smokers vs charges
sns.violinplot(x='smoker', y='charges', data=data, ax=axes[0])
axes[0].set_title('Violin Plot: Smoker vs Charges', fontweight='bold')
axes[0].set_xlabel('Smoker', fontweight='semibold')
axes[0].set_ylabel('Charges', fontweight='semibold')

# Distribution plot of charges for non-smokers
non_smokers = data[data['smoker'] == 'no']
sns.histplot(non_smokers['charges'], kde=True, ax=axes[1])
axes[1].set_title('Distribution of Charges for Non-Smokers', fontweight='bold')
axes[1].set_xlabel('Charges', fontweight='semibold')
axes[1].set_ylabel('Frequency', fontweight='semibold')

# Distribution plot of charges for smokers
smokers = data[data['smoker'] == 'yes']
sns.histplot(smokers['charges'], kde=True, ax=axes[2])
axes[2].set_title('Distribution of Charges for Smokers', fontweight='bold')
axes[2].set_xlabel('Charges', fontweight='semibold')
axes[2].set_ylabel('Frequency', fontweight='semibold')

# Adjust spacing between subplots
plt.subplots_adjust(wspace=0.3)

# Display the plot
plt.show()

"""Smoking patients spend more on health rather than non smokers. Let's see if charges depends on more variables or not."""

# Set up the figure and axis
plt.figure(figsize=(10, 6))

# Scatter plot with regression lines for smokers and non-smokers
g = sns.lmplot(x='age', y='charges', hue='smoker', data=data, legend=False)

# Set plot labels and title
g.fig.suptitle('Scatter Plot: Age vs Charges (Colored by Smoker)', fontweight='bold', y=1.02)
g.set_axis_labels('Age', 'Charges', fontweight='semibold')

# Make the visibility of each dot 50%
for artist in g.ax.collections:
    artist.set_alpha(0.25)

# Add legend on the left
leg = g.ax.legend(title='Smoker', title_fontsize='medium', loc='upper left')
for lh in leg.legend_handles:
    lh.set_alpha(1)  # Make legend markers opaque

# Display the plot
plt.show()

# Define the age bins
age_bins = [18, 25, 35, 45, 55, 65]
data['age_group'] = pd.cut(data['age'], bins=age_bins)

# Group by age group and smoker status and calculate average charges
grouped_data = data.groupby(['age_group', 'smoker'])['charges'].mean().reset_index()

# Plot the results
plt.figure(figsize=(12, 8))
sns.barplot(x='age_group', y='charges', hue='smoker', data=grouped_data)
plt.title('Average Charges by Age Group and Smoking Status', fontweight='bold')
plt.xlabel('Age Group', fontweight='semibold')
plt.ylabel('Average Charges', fontweight='semibold')
plt.legend(title='Smoker')
plt.xticks(rotation=45)
plt.show()

# Define the age bins
age_bins = [18, 25, 35, 45, 55, 65]
age_labels = ['18-24', '25-34', '35-44', '45-54', '55-64']
data['age_group'] = pd.cut(data['age'], bins=age_bins, labels=age_labels, right=False)

# Create a distribution plot for the age groups
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x='age_group', discrete=True)
plt.title('Distribution of Age Groups', fontweight='bold')
plt.xlabel('Age Group', fontweight='semibold')
plt.ylabel('Density', fontweight='semibold')
plt.show()

# Set up the figure and axis
plt.figure(figsize=(10, 6))

# Scatter plot with regression lines for smokers and non-smokers
g = sns.lmplot(x='bmi', y='charges', hue='smoker', data=data, legend=False)

# Set plot labels and title
g.fig.suptitle('Scatter Plot: bmi vs Charges (Colored by Smoker)', fontweight='bold', y=1.02)
g.set_axis_labels('bmi', 'Charges', fontweight='semibold')

# Make the visibility of each dot 50%
for artist in g.ax.collections:
    artist.set_alpha(0.25)

# Add legend on the left
leg = g.ax.legend(title='Smoker', title_fontsize='medium', loc='upper left')
for lh in leg.legend_handles:
    lh.set_alpha(1)  # Make legend markers opaque

# Display the plot
plt.show()

# Set up the figure and axis
plt.figure(figsize=(10, 6))

# Scatter plot with regression lines for smokers and non-smokers
g = sns.lmplot(x='bmi', y='log_charges', hue='smoker', data=data, legend=False)

# Set plot labels and title
g.fig.suptitle('Scatter Plot: bmi vs Log(Charges) (Colored by Smoker)', fontweight='bold', y=1.02)
g.set_axis_labels('bmi', 'Log(Charges)', fontweight='semibold')

# Make the visibility of each dot 50%
for artist in g.ax.collections:
    artist.set_alpha(0.25)

# Add legend on the left
leg = g.ax.legend(title='Smoker', title_fontsize='medium', loc='upper left')
for lh in leg.legend_handles:
    lh.set_alpha(1)  # Make legend markers opaque

# Display the plot
plt.show()

# Set up the figure and axis
plt.figure(figsize=(10, 6))

# Scatter plot with regression lines for smokers and non-smokers
g = sns.lmplot(x='age', y='bmi', hue='smoker', data=data, legend=False)

# Set plot labels and title
g.fig.suptitle('Scatter Plot: Age vs bmi (Colored by Smoker)', fontweight='bold', y=1.02)
g.set_axis_labels('age', 'bmi', fontweight='semibold')

# Make the visibility of each dot 50%
for artist in g.ax.collections:
    artist.set_alpha(0.25)

# Add legend on the left
leg = g.ax.legend(title='Smoker', title_fontsize='medium', loc='upper left')
for lh in leg.legend_handles:
    lh.set_alpha(1)  # Make legend markers opaque

# Display the plot
plt.show()

"""Interesting findings, if bmi increases of non-smoker, charges doesn't go much higher but for smokers, it exponentially increases."""

# Convert categorical variables to numerical codes
data_num = data.copy()
data_num['sex'] = data_num['sex'].astype('category').cat.codes
data_num['smoker'] = data_num['smoker'].astype('category').cat.codes
data_num = data_num.drop(['log_charges', 'age_group'], axis=1)
# One-hot encode the 'region' column with 0/1 values
data_encoded = pd.get_dummies(data_num, columns=['region'], dtype='uint8')

# Display the first few rows of the resulting dataframe
data_encoded.head()

"""Feature Selection

VIF
"""

X = data_encoded.drop('charges', axis=1)

# Add a constant term to the independent variable matrix
X = sm.add_constant(X)

vif = pd.DataFrame()
vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif['feature'] = X.columns

# Sort the VIF values in ascending order
vif = vif.sort_values('VIF', ascending=True)

print(vif)

"""ANOVA (Analysis of Variance)"""

# Assuming 'data_encoded' is your DataFrame with independent variables
X = data_encoded.drop('charges', axis=1)
y = data_encoded['charges']

anova_results = {}

for feature in X.columns:
    groups = X[feature].unique()
    data_groups = [y[X[feature] == group] for group in groups]

    f_value, p_value = f_oneway(*data_groups)
    anova_results[feature] = p_value

anova_results = pd.DataFrame.from_dict(anova_results, orient='index', columns=['p_value'])
anova_results = anova_results.sort_values(by='p_value', ascending=True)

print(anova_results)

"""RFECV (Recursive Feature Elimination with Cross-Validation):
RFECV is a method that recursively removes features and evaluates the model performance using cross-validation.
"""

X = data_numeric.drop('charges', axis=1)
y = data_numeric['charges']

model = LinearRegression()
rfecv = RFECV(estimator=model, step=1, cv=5, scoring='neg_mean_squared_error')
rfecv.fit(X, y)

print("Optimal number of features: {}".format(rfecv.n_features_))
print("Selected features: {}".format(X.columns[rfecv.support_]))
# Plot number of features vs. cross-validation scores
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross-validation score (MSE)")
plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])
plt.show()

"""**Random Forest Importance:**
Random Forest models can provide feature importance scores, which can be used for feature selection.
"""

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X, y)

importances = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_})
importances = importances.sort_values(by='importance', ascending=False)

print(importances)

"""Pearson Correlation Coefficient:
The Pearson Correlation Coefficient measures the linear relationship between two variables. You can calculate the correlation between each independent variable and the target variable to identify the most relevant features.
"""

corr_coefficients = X.corrwith(y)
corr_coefficients = corr_coefficients.sort_values(ascending=False)

print(corr_coefficients)

from sklearn.cluster import KMeans

# Select the features for clustering
features = data[['age', 'charges']]

# Perform K-means clustering
kmeans = KMeans(n_clusters=3, random_state=42)
cluster_labels = kmeans.fit_predict(features)

# Add cluster labels to the original dataframe
data['cluster'] = cluster_labels

# Create separate dataframes for each cluster
cluster_0 = data[data['cluster'] == 0]
cluster_1 = data[data['cluster'] == 1]
cluster_2 = data[data['cluster'] == 2]

# Print the size of each cluster
print("Cluster 0 size:", len(cluster_0))
print("Cluster 1 size:", len(cluster_1))
print("Cluster 2 size:", len(cluster_2))

# Display the first few rows of each cluster
print("\nCluster 0:")
print(cluster_0.head())
print("\nCluster 1:")
print(cluster_1.head())
print("\nCluster 2:")
print(cluster_2.head())
data.head()

# Select the features for clustering
cl_features = data[['age', 'charges']]

# Perform K-means clustering
kmeans = KMeans(n_clusters=3, random_state=42)
cluster_labels = kmeans.fit_predict(cl_features)

# Create a new DataFrame with the original data and cluster labels
clustered_data = data_numeric.copy()
clustered_data['cluster'] = cluster_labels

# Plot the original scatter plot with clusters
plt.figure(figsize=(12, 8))
sns.scatterplot(x='age', y='charges', hue='cluster', data=clustered_data, palette='viridis')
plt.title('Age vs Charges (KMeans Clustering)')
plt.xlabel('Age')
plt.ylabel('Charges')
plt.legend(title='Cluster')
plt.show()

# Create separate dataframes for each cluster
cluster_0 = data[data['cluster'] == 0]
cluster_1 = data[data['cluster'] == 1]
cluster_2 = data[data['cluster'] == 2]

# Plot separate graphs for each cluster
fig, axs = plt.subplots(1, 3, figsize=(18, 6))
fig.suptitle('Age vs Charges by Cluster (KMeans)', fontsize=16)

sns.scatterplot(x='age', y='charges', data=cluster_0, ax=axs[0], color='purple')
axs[0].set_title('Cluster 0')

sns.scatterplot(x='age', y='charges', data=cluster_1, ax=axs[1], color='green')
axs[1].set_title('Cluster 1')

sns.scatterplot(x='age', y='charges', data=cluster_2, ax=axs[2], color='orange')
axs[2].set_title('Cluster 2')

for ax in axs:
    ax.set_xlabel('Age')
    ax.set_ylabel('Charges')

plt.tight_layout()
plt.show()

# Print cluster sizes
for i in range(3):
    print(f"Cluster {i} size:", len(data[data['cluster'] == i]))

data.head()

# Summary statistics of each cluster
cluster_summary = clustered_data.groupby('cluster').mean()
print(cluster_summary)

# Plot distributions of other features for each cluster
fig, axs = plt.subplots(3, 2, figsize=(18, 18))
fig.suptitle('Feature Distributions by Cluster', fontsize=16)

sns.histplot(clustered_data[clustered_data['cluster'] == 0]['bmi'], ax=axs[0, 0], color='purple', kde=True)
axs[0, 0].set_title('Cluster 0 - BMI')

sns.histplot(clustered_data[clustered_data['cluster'] == 1]['bmi'], ax=axs[0, 1], color='green', kde=True)
axs[0, 1].set_title('Cluster 1 - BMI')

sns.histplot(clustered_data[clustered_data['cluster'] == 2]['bmi'], ax=axs[1, 0], color='orange', kde=True)
axs[1, 0].set_title('Cluster 2 - BMI')

sns.histplot(clustered_data[clustered_data['cluster'] == 0]['children'], ax=axs[1, 1], color='purple', kde=True)
axs[1, 1].set_title('Cluster 0 - Children')

sns.histplot(clustered_data[clustered_data['cluster'] == 1]['children'], ax=axs[2, 0], color='green', kde=True)
axs[2, 0].set_title('Cluster 1 - Children')

sns.histplot(clustered_data[clustered_data['cluster'] == 2]['children'], ax=axs[2, 1], color='orange', kde=True)
axs[2, 1].set_title('Cluster 2 - Children')

plt.tight_layout()
plt.show()

from sklearn.tree import DecisionTreeClassifier, plot_tree

# Select relevant features
features = ['age', 'charges', 'bmi', 'children', 'smoker', 'region']
X = data_numeric[features]
y = clustered_data['cluster']

# Train a decision tree classifier
clf = DecisionTreeClassifier(max_depth=3, random_state=0)
clf.fit(X, y)

# Plot the decision tree
plt.figure(figsize=(20, 10))
plot_tree(clf, feature_names=features, class_names=['Cluster 0', 'Cluster 1', 'Cluster 2'], filled=True)
plt.title('Decision Tree for Cluster Formation')
plt.show()

# Add cluster labels to the original dataframe
data['cluster'] = cluster_labels\

# Display the first few rows of each cluster
print("\nCluster 0:")
cluster_0.head()

print("\nCluster 1:")
cluster_1.head()

print("\nCluster 2:")
cluster_2.head()

# Function to create subplots for each cluster
def plot_cluster_subplots(cluster_data, cluster_num):
    fig, axs = plt.subplots(2, 3, figsize=(20, 15))
    fig.suptitle(f'Cluster {cluster_num} Relationships', fontsize=16)

    # Charges vs Age
    sns.scatterplot(x='age', y='charges', data=cluster_data, ax=axs[0, 0])
    axs[0, 0].set_title('Charges vs Age')

    # Charges vs BMI
    sns.scatterplot(x='bmi', y='charges', data=cluster_data, ax=axs[0, 1])
    axs[0, 1].set_title('Charges vs BMI')

    # Charges vs Sex
    sns.boxplot(x='sex', y='charges', data=cluster_data, ax=axs[0, 2])
    axs[0, 2].set_title('Charges vs Sex')

    # Charges vs Smoker
    sns.boxplot(x='smoker', y='charges', data=cluster_data, ax=axs[1, 0])
    axs[1, 0].set_title('Charges vs Smoker')

    # Charges vs Region
    sns.boxplot(x='region', y='charges', data=cluster_data, ax=axs[1, 1])
    axs[1, 1].set_title('Charges vs Region')

    # Charges vs Children
    sns.boxplot(x='children', y='charges', data=cluster_data, ax=axs[1, 2])
    axs[1, 2].set_title('Charges vs Children')

    plt.tight_layout()
    plt.show()

# Plot subplots for each cluster
for i in range(3):
    cluster_data = clustered_data[clustered_data['cluster'] == i]
    plot_cluster_subplots(cluster_data, i)

# Print cluster sizes
for i in range(3):
    print(f"Cluster {i} size:", len(clustered_data[clustered_data['cluster'] == i]))

"""Traditional Regression"""

data.head()

data_encoded.head()

data_numeric.head()

# Split the data
X = data_numeric[['age', 'bmi', 'sex', 'smoker', 'region', 'children']]
y = data_numeric['charges']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Function to evaluate and print model performance
def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    print(f"{model_name}:")
    print(f"MSE: {mse:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"R2 Score: {r2:.4f}")
    print()

# Function to plot predicted vs actual values
def plot_predictions(y_true, y_pred, model_name):
    plt.figure(figsize=(10, 6))
    plt.scatter(y_true, y_pred, alpha=0.5, label='Predicted vs Actual')
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--r', label='Prediction')
    plt.xlabel('Actual Charges')
    plt.ylabel('Predicted Charges')
    plt.title(f'{model_name} - Predicted vs Actual')
    plt.legend()  # Ensure legend is shown with labels
    plt.show()



# Create and fit the model
linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)

# Predict and evaluate
y_pred_train = linear_reg.predict(X_train)
y_pred_test = linear_reg.predict(X_test)

evaluate_model(y_train, y_pred_train, "Linear Regression (Train)")
evaluate_model(y_test, y_pred_test, "Linear Regression (Test)")

# Linear Regression
plot_predictions(y_test, linear_reg.predict(X_test), "Linear Regression")

# Calculate residuals
residuals_train_linear = y_train - y_pred_train
residuals_test_linear = y_test - y_pred_test

# Plot residuals
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_pred_train, residuals_train_linear)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Train) - Linear Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.subplot(1, 2, 2)
plt.scatter(y_pred_test, residuals_test_linear)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Test) - Linear Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.show()

# Transform to polynomial features
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Create and fit the model
poly_reg = LinearRegression()
poly_reg.fit(X_train_poly, y_train)

# Predict and evaluate
y_pred_train = poly_reg.predict(X_train_poly)
y_pred_test = poly_reg.predict(X_test_poly)

evaluate_model(y_train, y_pred_train, "Polynomial Regression (Train)")
evaluate_model(y_test, y_pred_test, "Polynomial Regression (Test)")

plot_predictions(y_test, poly_reg.predict(poly.transform(X_test)), "Polynomial Regression")

# Calculate residuals
residuals_train_poly = y_train - y_pred_train
residuals_test_poly = y_test - y_pred_test

# Plot residuals
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_pred_train, residuals_train_poly)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Train) - Polynomial Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.subplot(1, 2, 2)
plt.scatter(y_pred_test, residuals_test_poly)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Test) - Polynomial Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.show()

# Create and fit the model
ridge_reg = Ridge(alpha=1.0)
ridge_reg.fit(X_train, y_train)

# Predict and evaluate
y_pred_train = ridge_reg.predict(X_train)
y_pred_test = ridge_reg.predict(X_test)

evaluate_model(y_train, y_pred_train, "Ridge Regression (Train)")
evaluate_model(y_test, y_pred_test, "Ridge Regression (Test)")

plot_predictions(y_test, ridge_reg.predict(X_test), "Ridge Regression")

# Calculate residuals
residuals_train_ridge = y_train - y_pred_train
residuals_test_ridge = y_test - y_pred_test

# Plot residuals
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_pred_train, residuals_train_ridge)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Train) - Ridge Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.subplot(1, 2, 2)
plt.scatter(y_pred_test, residuals_test_ridge)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Test) - Ridge Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.show()

# Create and fit the model
lasso_reg = Lasso(alpha=1.0)
lasso_reg.fit(X_train, y_train)

# Predict and evaluate
y_pred_train = lasso_reg.predict(X_train)
y_pred_test = lasso_reg.predict(X_test)

evaluate_model(y_train, y_pred_train, "Lasso Regression (Train)")
evaluate_model(y_test, y_pred_test, "Lasso Regression (Test)")

plot_predictions(y_test, lasso_reg.predict(X_test), "Lasso Regression")

# Calculate residuals
residuals_train_lasso = y_train - y_pred_train
residuals_test_lasso = y_test - y_pred_test

# Plot residuals
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_pred_train, residuals_train_lasso)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Train) - Lasso Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.subplot(1, 2, 2)
plt.scatter(y_pred_test, residuals_test_lasso)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residuals vs Predicted (Test) - Lasso Regression')
plt.xlabel('Predicted values')
plt.ylabel('Residuals')

plt.show()

"""Polynomial Regression has the best performance among the models in terms of MSE, RMSE, and R² scores for both training and testing data:

It has the lowest MSE and RMSE values, indicating it has the smallest errors.
It has the highest R² score, indicating it explains the most variance in the target variable.
"""

# Function to plot predicted vs actual values
def plot_predictions(ax, y_true, y_pred, model_name):
    ax.scatter(y_true, y_pred, alpha=0.5, label='Actual')
    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--r', label='Predicted Trend')
    ax.set_xlabel('Actual Charges')
    ax.set_ylabel('Predicted Charges')
    ax.set_title(f'{model_name} - Predicted vs Actual')
    ax.legend()

# Create a figure and subplots
fig, axs = plt.subplots(1, 4, figsize=(20, 5))

# Plot for Linear Regression
plot_predictions(axs[0], y_test, linear_reg.predict(X_test), "Linear Regression")

# Plot for Polynomial Regressio
plot_predictions(axs[1], y_test, poly_reg.predict(poly.transform(X_test)), "Polynomial Regression")

# Plot for Ridge Regression
plot_predictions(axs[2], y_test, ridge_reg.predict(X_test), "Ridge Regression")

# Plot for Lasso Regression
plot_predictions(axs[3], y_test, lasso_reg.predict(X_test), "Lasso Regression")

# Adjust layout
plt.tight_layout()
plt.show()

"""Using hyperparameter tuning"""



from sklearn.model_selection import GridSearchCV
# Define the pipeline with PolynomialFeatures and LinearRegression
poly_reg = Pipeline([
    ('scaler', StandardScaler()),  # Optional: Normalize your features if needed
    ('poly', PolynomialFeatures()),  # PolynomialFeatures with default settings
    ('linear_reg', LinearRegression())
])

# Define the parameter grid for GridSearchCV
param_grid = {
    'poly__degree': [2, 3, 4, 5],  # Degrees of polynomial features to try
    'poly__interaction_only': [True, False],  # Whether to include only interaction features
}

# Instantiate GridSearchCV
grid_search = GridSearchCV(estimator=poly_reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

# Get the best model
best_poly_reg = grid_search.best_estimator_

# Predict with best model
y_pred_train = best_poly_reg.predict(X_train)
y_pred_test = best_poly_reg.predict(X_test)

evaluate_model(y_train, y_pred_train, "Polynomial Regression (Train)")
evaluate_model(y_test, y_pred_test, "Polynomial Regression (Test)")

# Print the best parameters found by GridSearchCV
print("Best parameters found by GridSearchCV:")
print(grid_search.best_params_)

# Plotting actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_test, color='blue', alpha=0.5, label='Actual')
plt.plot(y_test, y_test, color='red', label='Prediction Trend')
plt.title('Actual vs Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

# Define the pipeline with StandardScaler and Ridge regression
ridge_reg = Pipeline([
    ('scaler', StandardScaler()),
    ('ridge', Ridge())
])

# Define the parameter grid for GridSearchCV
param_grid = {
    'ridge__alpha': [0.001, 0.01, 0.1, 1.0, 10.0],  # Regularization strength
    'ridge__fit_intercept': [True, False],  # Whether to fit intercept
    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solver type
    'ridge__max_iter': [None, 100, 1000, 10000],  # Maximum number of iterations
}

# Instantiate GridSearchCV
grid_search = GridSearchCV(estimator=ridge_reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

# Get the best model
best_ridge_reg = grid_search.best_estimator_

# Predict with best model
y_pred_train = best_ridge_reg.predict(X_train)
y_pred_test = best_ridge_reg.predict(X_test)

# Evaluate best model
def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    print(f"{model_name}:")
    print(f"MSE: {mse:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"R2 Score: {r2:.4f}")
    print()

evaluate_model(y_train, y_pred_train, "Ridge Regression (Train)")
evaluate_model(y_test, y_pred_test, "Ridge Regression (Test)")

# Plotting actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_test, color='blue', alpha=0.5, label='Actual vs Predicted')
plt.plot(y_test, y_test, color='red', label='Prediction Trend')
plt.title('Actual vs Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

# Print the best parameters found by GridSearchCV
print("Best parameters found by GridSearchCV:")
print(grid_search.best_params_)

# Define the pipeline with StandardScaler and Lasso regression
lasso_reg = Pipeline([
    ('scaler', StandardScaler()),
    ('lasso', Lasso())
])

# Define the parameter grid for GridSearchCV
param_grid = {
    'lasso__alpha': [0.001, 0.01, 0.1, 1.0, 10.0],  # Regularization strength
    'lasso__fit_intercept': [True, False],  # Whether to fit intercept
    'lasso__max_iter': [1000, 2000, 3000],  # Maximum number of iterations
    'lasso__selection': ['cyclic', 'random'],  # Method used to select features
}

# Instantiate GridSearchCV
grid_search = GridSearchCV(estimator=lasso_reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

# Get the best model
best_lasso_reg = grid_search.best_estimator_

# Predict with best model
y_pred_train = best_lasso_reg.predict(X_train)
y_pred_test = best_lasso_reg.predict(X_test)

evaluate_model(y_train, y_pred_train, "Lasso Regression (Train)")
evaluate_model(y_test, y_pred_test, "Lasso Regression (Test)")

# Plotting actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_test, color='blue', alpha=0.5, label='Actual vs Predicted')
plt.plot(y_test, y_test, color='red', label='Prediction Trend')
plt.title('Actual vs Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

# Print the best parameters found by GridSearchCV
print("Best parameters found by GridSearchCV:")
print(grid_search.best_params_)

"""From the results, it appears that the metrics (MSE, RMSE, R2 Score) for both training and test sets remain almost identical before and after using GridSearchCV. This suggests that the hyperparameters chosen by GridSearchCV did not significantly alter the model's performance metrics in this particular case.

### Quantile Regression
"""

# Separate predictors (X) and response variable (y)
# Split the data
X = data_numeric[['age', 'bmi', 'sex', 'smoker', 'region', 'children']]
y = data_numeric['charges']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Add constant to X for the intercept term in the model
X_train = sm.add_constant(X_train)
X_test = sm.add_constant(X_test)

# Quantile levels to estimate
quantiles = [0.25, 0.50, 0.75]
max_iter = 10000  # Maximum number of iterations for optimization
# Fit quantile regression models
models = {}
for quantile in quantiles:
    model = sm.QuantReg(y_train, X_train).fit(q=quantile, max_iter=max_iter)
    models[quantile] = model

# Print summary of each model
for quantile, model in models.items():
    print(f"Quantile Regression Results for Quantile {quantile}:")
    print(model.summary())
    print()

# Predictions at different quantiles
quantile_predictions = {}
for quantile, model in models.items():
    y_pred = model.predict(X_test)
    quantile_predictions[quantile] = y_pred

# Plotting actual vs predicted values
plt.figure(figsize=(10, 6))

# Plot each quantile
for quantile, color in zip(quantiles, ['blue', 'green', 'red', 'blue', 'purple']):
    plt.scatter(y_test, quantile_predictions[quantile], color=color, alpha=0.5, label=f'Quantile {quantile}')

plt.plot(y_test, y_test, color='gray', label='Prediction Trend')
plt.title('Quantile Regression - Actual vs Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

"""
Quantile 0.25 (25th percentile):

Pseudo R-squared: 0.6019

Significant Predictors: Age, BMI, Sex, Smoker, Region, Children

Interpretation: Similar significant predictors as quantile 0.1, with slightly different coefficient values indicating their impact on charges at the 25th percentile of the distribution.

Quantile 0.5 (50th percentile - Median):

Pseudo R-squared: 0.5828

Significant Predictors: Age, BMI, Sex, Smoker, Region, Children

Interpretation: Median quantile shows that similar predictors impact charges, but with different coefficient magnitudes compared to lower quantiles, reflecting the middle of the charge distribution.

Quantile 0.75 (75th percentile):

Pseudo R-squared: 0.6465

Significant Predictors: Age, BMI, Sex, Smoker, Region, Children

Interpretation: At the 75th percentile, predictors continue to have significant effects on charges, with higher coefficients for some predictors compared to lower quantiles, indicating a higher charge distribution.

Quantile 0.9 (90th percentile):

Pseudo R-squared: 0.5600

Significant Predictors: Age, BMI, Smoker, Children (Sex and Region are not significant)

Interpretation: At the 90th percentile, age, BMI, smoking status, and number of children remain significant predictors, while sex and region do not significantly affect charges. The model suggests larger coefficients for BMI and smoker status at this higher quantile."""

# Separate predictors (X) and response variable (y)
# Split the data
X = data_numeric[['age', 'bmi', 'sex', 'smoker', 'region', 'children']]
y = data_numeric['charges']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Add constant to X for the intercept term in the model
X_train = sm.add_constant(X_train)
X_test = sm.add_constant(X_test)

# Quantile levels to estimate
quantiles = [0.1, 0.2, 0.3, 0.4, 0.50, 0.6, 0.7, 0.8, 0.9]
max_iter = 10000  # Maximum number of iterations for optimization
# Fit quantile regression models
models = {}
for quantile in quantiles:
    model = sm.QuantReg(y_train, X_train).fit(q=quantile, max_iter=max_iter)
    models[quantile] = model

# Print summary of each model
for quantile, model in models.items():
    print(f"Quantile Regression Results for Quantile {quantile}:")
    print(model.summary())
    print()

# Predictions at different quantiles
quantile_predictions = {}
for quantile, model in models.items():
    y_pred = model.predict(X_test)
    quantile_predictions[quantile] = y_pred

# Plotting actual vs predicted values
plt.figure(figsize=(10, 6))

# Plot each quantile
for quantile, color in zip(quantiles, ['blue', 'green', 'orange', 'red', 'purple', 'cyan', 'magenta', 'yellow', 'brown', 'pink']):
    plt.scatter(y_test, quantile_predictions[quantile], color=color, alpha=0.5, label=f'Quantile {quantile}')

plt.plot(y_test, y_test, color='gray', label='Prediction Trend')
plt.title('Quantile Regression - Actual vs Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

"""The pseudo R-squared values range between approximately 0.56 to 0.64 across quantiles, indicating that the models explain a substantial portion of the variability in medical charges.

As quantiles increase (moving from lower to higher percentiles), the coefficients generally increase in magnitude, indicating that the effects of age, BMI, smoking, and number of children on medical charges become more pronounced at higher charges.

Age and BMI: Older age and higher BMI consistently lead to higher medical charges.

Smoking: Smoking is a significant predictor of higher medical charges across all quantiles.

Sex and Region: The impact of sex and region on medical charges varies but generally shows smaller effects compared to age, BMI, and smoking.
Children: Having more children is associated with higher medical charges.
"""

from sklearn.tree import DecisionTreeClassifier, plot_tree

# Select features for clustering
features = ['age', 'charges']
X = data_numeric[features]

# Standardize the data
scaler = StandardScaler()
scaled_X = scaler.fit_transform(X)

# Apply K-means clustering
kmeans = KMeans(n_clusters=3, random_state=0)
data_numeric['cluster'] = kmeans.fit_predict(scaled_X)

# Plot age vs. charges colored by cluster
plt.figure(figsize=(10, 6))
sns.scatterplot(x='age', y='charges', hue='cluster', palette='Set1', data=data_numeric)
plt.title('Age vs Charges (colored by Clusters)')
plt.xlabel('Age')
plt.ylabel('Charges')
plt.show()

# Train a Decision Tree Classifier
clf = DecisionTreeClassifier(max_depth=3, random_state=0)
clf.fit(X, data_numeric['cluster'])

# Create a mesh grid
x_min, x_max = X['age'].min() - 1, X['age'].max() + 1
y_min, y_max = X['charges'].min() - 1, X['charges'].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 100))

# Predict clusters for each point in the mesh grid
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the decision boundaries
plt.figure(figsize=(10, 6))
plt.contourf(xx, yy, Z, alpha=0.4, cmap='Set1')
sns.scatterplot(x='age', y='charges', hue='cluster', data=data_numeric, palette='Set1', edgecolor='k')
plt.title('Decision Boundaries with Decision Tree')
plt.xlabel('Age')
plt.ylabel('Charges')
plt.show()

# Plot the decision tree
plt.figure(figsize=(20,10))
plot_tree(clf, feature_names=features, class_names=['Cluster 0', 'Cluster 1', 'Cluster 2'], filled=True)
plt.show()

"""well we have observed that there are 3 cluster, also we;ve tried to see if there are another variables helped it to make these clusters

there might be missing variable, these would be in limitations

for regression:
r square method

check the residual after fitting the model
normality assumption
constant variable assumption

For variable selection:
Inference oberservation
cook distance

Refit the Model


If we decide to remove these points, we'll refit the model and compare the results to see if the model's performance improves.

Finding high leverage points and outliers
"""

target_column = 'charges'
X = data_numeric.drop(columns=[target_column])
y = data_numeric[target_column]

# Add a constant term for the intercept
X = sm.add_constant(X)

# Fit the model
model = sm.OLS(y, X).fit()

# Calculate influence measures
influence = model.get_influence()

# Leverage (hat values)
leverage = influence.hat_matrix_diag

# Standardized residuals
standardized_residuals = influence.resid_studentized_internal #if >3 then standard value, how we defined the outlier, is it absolute value or what

# Cook's distance
cooks_d = influence.cooks_distance[0]

# Identify high leverage points
high_leverage_threshold = 2 * (X.shape[1] / X.shape[0])  # Common threshold
high_leverage_points = np.where(leverage > high_leverage_threshold)[0]

# Identify outliers
outlier_threshold = 2  # Common threshold for standardized residuals
outliers = np.where(np.abs(standardized_residuals) > outlier_threshold)[0]

# Combine influential points, high leverage points, and outliers
combined_indices = np.unique(np.concatenate((high_leverage_points, outliers)))

# Identify points with high Cook's distance
cooks_d_threshold = 4 / len(X)
high_cooks_d_points = np.where(cooks_d > cooks_d_threshold)[0]

# Combine influential points that are also high leverage points or outliers above Cook's distance threshold
combined_indices = np.unique(np.concatenate((
    np.intersect1d(high_leverage_points, high_cooks_d_points),
    np.intersect1d(outliers, high_cooks_d_points)
)))

# Plot Cook's distance
plt.figure(figsize=(10, 6))
plt.stem(np.arange(len(cooks_d)), cooks_d, markerfmt=",", linefmt='b-', basefmt=' ', label='Cook\'s Distance')

# Highlight high leverage points
plt.scatter(high_leverage_points, cooks_d[high_leverage_points], color='red', label='High Leverage Points', zorder=3)

# Highlight outliers
plt.scatter(outliers, cooks_d[outliers], color='orange', label='Outliers', zorder=3)

plt.title("Cook's Distance with High Leverage Points and Outliers")
plt.xlabel("Observation Index")
plt.ylabel("Cook's Distance")
plt.axhline(y=4 / len(X), color='r', linestyle='--', label='Threshold (4/n)')
plt.legend()
plt.show()

# Display influential points summary
influential_points_summary = pd.DataFrame({
    'Index': combined_indices,
    'Leverage': leverage[combined_indices],
    'Standardized Residuals': standardized_residuals[combined_indices],
    'Cook\'s Distance': cooks_d[combined_indices]
})

influential_points_summary

# Split the cleaned data into training and testing sets
X_train_wo, X_test_wo, y_train_wo, y_test_wo = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model again
linear_reg_wo = LinearRegression()
linear_reg_wo.fit(X_train_wo, y_train_wo)

# Predict and evaluate
y_pred_train_wo = linear_reg_wo.predict(X_train_wo)
y_pred_test_wo = linear_reg_wo.predict(X_test_wo)

# Define the evaluate_model function to calculate evaluation metrics
def evaluate_model(y_true, y_pred, model_name):
    from sklearn.metrics import mean_squared_error, r2_score
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train_wo, y_pred_train_wo, "Linear Regression (Train) - Original")
evaluate_model(y_test_wo, y_pred_test_wo, "Linear Regression (Test) - Original")

# Calculate residuals for the training set
residuals_train_wo = y_train_wo - y_pred_train_wo

# Calculate residuals for the test set
residuals_test_wo = y_test_wo - y_pred_test_wo

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_wo, residuals_train_wo, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_wo, residuals_test_wo, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Original Residuals vs Predicted Values (Training and Test Sets)')
plt.legend()
plt.show()

"""remving"""

# Remove high leverage points and outliers from the dataset
data_cleaned = data_numeric.drop(index=combined_indices)

# Split the cleaned data into features and target
X_cleaned = data_cleaned.drop(columns=[target_column])
y_cleaned = data_cleaned[target_column]

# Add a constant term for the intercept
X_cleaned = sm.add_constant(X_cleaned)

# Split the cleaned data into training and testing sets
X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)

# Fit the model again
linear_reg_cleaned = LinearRegression()
linear_reg_cleaned.fit(X_train_cleaned, y_train_cleaned)

# Predict and evaluate
y_pred_train_cleaned = linear_reg_cleaned.predict(X_train_cleaned)
y_pred_test_cleaned = linear_reg_cleaned.predict(X_test_cleaned)

# Define the evaluate_model function to calculate evaluation metrics
def evaluate_model(y_true, y_pred, model_name):
    from sklearn.metrics import mean_squared_error, r2_score
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train_cleaned, y_pred_train_cleaned, "Linear Regression (Train) - Cleaned")
evaluate_model(y_test_cleaned, y_pred_test_cleaned, "Linear Regression (Test) - Cleaned")

"""Calculating and visualize the residuals"""

# Calculate residuals for the training set
residuals_train_cleaned = y_train_cleaned - y_pred_train_cleaned

# Calculate residuals for the test set
residuals_test_cleaned = y_test_cleaned - y_pred_test_cleaned

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_cleaned, residuals_train_cleaned, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_cleaned, residuals_test_cleaned, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Cleaned Residuals vs Predicted Values (Training and Test Sets)')
plt.legend()
plt.show()

"""XGBoost (Extreme Gradient Boosting)"""

# Split the Original data into training and testing sets
X_train_wo, X_test_wo, y_train_wo, y_test_wo = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the XGBRegressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Fit the model
xgb_reg.fit(X_train, y_train)

# Predict
y_pred_train = xgb_reg.predict(X_train)
y_pred_test = xgb_reg.predict(X_test)

def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train, y_pred_train, "XGBoost Regression (Train)")
evaluate_model(y_test, y_pred_test, "XGBoost Regression (Test)")

# Calculate residuals for the training set
residuals_train = y_train - y_pred_train

# Calculate residuals for the test set
residuals_test = y_test - y_pred_test

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train, residuals_train, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test, residuals_test, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Original data XGBoost (Residuals vs Predicted Values)')
plt.legend()
plt.show()

# Initialize the XGBRegressor
xgb_reg2 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Fit the model
xgb_reg2.fit(X_train_cleaned, y_train_cleaned)

# Predict
y_pred_train_cleaned_xg = xgb_reg2.predict(X_train_cleaned)
y_pred_test_cleaned_xg = xgb_reg2.predict(X_test_cleaned)

def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train_cleaned, y_pred_train_cleaned_xg, "XGBoost Regression (Train)")
evaluate_model(y_test_cleaned, y_pred_test_cleaned_xg, "XGBoost Regression (Test)")

# Calculate residuals for the training set
residuals_train_xg = y_train_cleaned - y_pred_train_cleaned_xg

# Calculate residuals for the test set
residuals_test_xg = y_test_cleaned - y_pred_test_cleaned_xg

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_cleaned_xg, residuals_train_xg, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_cleaned_xg, residuals_test_xg, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Original data XGBoost (Residuals vs Predicted Values)')
plt.legend()
plt.show()

def quantile_regression(q, X_train, y_train, X_test, y_test, max_iter=10000):
    # Fit the model with increased maximum iterations
    mod = sm.QuantReg(y_train, X_train)
    res = mod.fit(q=q, max_iter=max_iter)

    # Predict
    y_pred_train = res.predict(X_train)
    y_pred_test = res.predict(X_test)

    # Evaluate
    mse_train = mean_squared_error(y_train, y_pred_train)
    mse_test = mean_squared_error(y_test, y_pred_test)
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)

    print(f'Quantile {q} - Train MSE: {mse_train:.4f}, R2: {r2_train:.4f}')
    print(f'Quantile {q} - Test MSE: {mse_test:.4f}, R2: {r2_test:.4f}')

    return res, y_pred_train, y_pred_test

quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    res, y_pred_train_quant, y_pred_test_quant = quantile_regression(q, X_train_wo, y_train_wo, X_test_wo, y_test_wo)
    results[q] = (res, y_pred_train_quant, y_pred_test_quant)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_quant, y_pred_test_quant = results[q]

    # Calculate residuals for the training set
    residuals_train_quant = y_train_wo - y_pred_train_quant

    # Calculate residuals for the test set
    residuals_test_quant = y_test_wo - y_pred_test_quant

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_quant, residuals_train_quant, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_quant, residuals_test_quant, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_quant, y_pred_test_quant = results[q]

    # Calculate residuals for the training set
    residuals_train_quant = y_train_wo - y_pred_train_quant

    # Calculate residuals for the test set
    residuals_test_quant = y_test_wo - y_pred_test_quant

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_quant, residuals_train_quant, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_quant, residuals_test_quant, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""For cleaned data"""

quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    res, y_pred_train_cq, y_pred_test_cq = quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    results[q] = (res, y_pred_train_cq, y_pred_test_cq)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Calculate residuals for the training set
    residuals_train_cq = y_train_cleaned - y_pred_train_cq

    # Calculate residuals for the test set
    residuals_test_cq = y_test_cleaned - y_pred_test_cq

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_cq, residuals_train_cq, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_cq, residuals_test_cq, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Cleaned Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()



# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Calculate residuals for the training set
    residuals_train_cq = y_train_cleaned - y_pred_train_cq

    # Calculate residuals for the test set
    residuals_test_cq= y_test_cleaned - y_pred_test_cq

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_cq, residuals_train_cq, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_cq, residuals_test_cq, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""Using XGBoost (Extreme Gradient Boosting)"""

# Define a function to fit and predict using XGBoost for quantile regression
def xgboost_quantile_regression(q, X_train, y_train, X_test, y_test):
    # Custom objective function for quantile regression
    def quantile_obj(y_true, y_pred):
        e = y_true - y_pred
        grad = np.where(e > 0, -q, 1 - q)
        hess = np.ones_like(y_true)
        return grad, hess

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)

    params = {
        'eta': 0.1,
        'max_depth': 3,
        'objective': quantile_obj
    }

    num_boost_round = 100
    model = xgb.train(params, dtrain, num_boost_round)

    y_pred_train = model.predict(dtrain)
    y_pred_test = model.predict(dtest)

    # Evaluate
    mse_train = mean_squared_error(y_train, y_pred_train)
    mse_test = mean_squared_error(y_test, y_pred_test)
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)

    print(f'Quantile {q} - Train MSE: {mse_train:.4f}, R2: {r2_train:.4f}')
    print(f'Quantile {q} - Test MSE: {mse_test:.4f}, R2: {r2_test:.4f}')

    return model, y_pred_train, y_pred_test

# Define a function for the quantile loss
def quantile_loss(q, y_true, y_pred):
    e = y_true - y_pred
    return np.mean(np.maximum(q * e, (q - 1) * e))

# Define a function to fit and predict using XGBoost for quantile regression
def xgboost_quantile_regression(q, X_train, y_train, X_test, y_test):
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)

    params = {
        'eta': 0.1,
        'max_depth': 3,
        'objective': 'reg:absoluteerror',
        'alpha': q
    }

    num_boost_round = 100
    model = xgb.train(params, dtrain, num_boost_round)

    y_pred_train = model.predict(dtrain)
    y_pred_test = model.predict(dtest)

    # Evaluate
    mse_train = mean_squared_error(y_train, y_pred_train)
    mse_test = mean_squared_error(y_test, y_pred_test)
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)

    print(f'Quantile {q} - Train MSE: {mse_train:.4f}, R2: {r2_train:.4f}')
    print(f'Quantile {q} - Test MSE: {mse_test:.4f}, R2: {r2_test:.4f}')

    return model, y_pred_train, y_pred_test

# Perform XGBoost quantile regression for 0.25, 0.5, and 0.75 quantiles
quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    model, y_pred_train_quant, y_pred_test_quant = xgboost_quantile_regression(q, X_train_wo, y_train_wo, X_test_wo, y_test_wo)
    results[q] = (model, y_pred_train_quant, y_pred_test_quant)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_qxg, y_pred_test_qxg = results[q]

    # Calculate residuals for the training set
    residuals_train_qxg = y_train_wo - y_pred_train_qxg

    # Calculate residuals for the test set
    residuals_test_qxg = y_test_wo - y_pred_test_qxg

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_qxg, residuals_train_qxg, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_qxg, residuals_test_qxg, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_qxg, y_pred_test_qxg = results[q]

    # Calculate residuals for the training set
    residuals_train_qxg = y_train_wo - y_pred_train_qxg

    # Calculate residuals for the test set
    residuals_test_qxg = y_test_wo - y_pred_test_qxg

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_qxg, residuals_train_qxg, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_qxg, residuals_test_qxg, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""On cleaned data"""

# Perform XGBoost quantile regression for 0.25, 0.5, and 0.75 quantiles
quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    model, y_pred_train_qxgc, y_pred_test_qxgc = xgboost_quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    results[q] = (model, y_pred_train_qxgc, y_pred_test_qxgc)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_qxgc, y_pred_test_qxgc = results[q]

    # Calculate residuals for the training set
    residuals_train_qxgc = y_train_cleaned - y_pred_train_qxgc

    # Calculate residuals for the test set
    residuals_test_qxgc = y_test_cleaned - y_pred_test_qxgc

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_qxgc, residuals_train_qxgc, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_qxgc, residuals_test_qxgc, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_qxgc, y_pred_test_qxgc = results[q]

    # Calculate residuals for the training set
    residuals_train_qxgc = y_train_cleaned - y_pred_train_qxgc

    # Calculate residuals for the test set
    residuals_test_qxgc = y_test_cleaned - y_pred_test_qxgc

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_qxgc, residuals_train_qxgc, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_qxgc, residuals_test_qxgc, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""After Feature selection
Most significant features are:

1. Smoker

2. BMI

3. Age

Lets select only these feature and find outliers and high leverege points and again
"""

target_column = 'charges'
selected_features = ['smoker', 'bmi', 'age']
X = data_numeric[selected_features]
y = data_numeric[target_column]

# Add a constant term for the intercept
X = sm.add_constant(X)

# Fit the model
model = sm.OLS(y, X).fit()

# Calculate influence measures
influence = model.get_influence()

# Leverage (hat values)
leverage = influence.hat_matrix_diag

# Standardized residuals
standardized_residuals = influence.resid_studentized_internal

# Cook's distance
cooks_d = influence.cooks_distance[0]

# Identify high leverage points
high_leverage_threshold = 2 * (X.shape[1] / X.shape[0])  # Common threshold
high_leverage_points = np.where(leverage > high_leverage_threshold)[0]

# Identify outliers
outlier_threshold = 2  # Common threshold for standardized residuals
outliers = np.where(np.abs(standardized_residuals) > outlier_threshold)[0]

# Combine influential points, high leverage points, and outliers
combined_indices = np.unique(np.concatenate((high_leverage_points, outliers)))

# Plot Cook's distance
plt.figure(figsize=(10, 6))
plt.stem(np.arange(len(cooks_d)), cooks_d, markerfmt=",", linefmt='b-', basefmt=' ', label='Cook\'s Distance')

# Highlight high leverage points
plt.scatter(high_leverage_points, cooks_d[high_leverage_points], color='red', label='High Leverage Points', zorder=3)

# Highlight outliers
plt.scatter(outliers, cooks_d[outliers], color='orange', label='Outliers', zorder=3)

plt.title("Cook's Distance with High Leverage Points and Outliers")
plt.xlabel("Observation Index")
plt.ylabel("Cook's Distance")
plt.axhline(y=4 / len(X), color='r', linestyle='--', label='Threshold (4/n)')
plt.legend()
plt.show()

# Display influential points summary
influential_points_summary = pd.DataFrame({
    'Index': combined_indices,
    'Leverage': leverage[combined_indices],
    'Standardized Residuals': standardized_residuals[combined_indices],
    'Cook\'s Distance': cooks_d[combined_indices]
})

influential_points_summary

X

y

"""Fitting linear regression model without removing these outliers and high levereage poings"""

# Split the cleaned data into training and testing sets
X_train_wo, X_test_wo, y_train_wo, y_test_wo = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model again
linear_reg_wo = LinearRegression()
linear_reg_wo.fit(X_train_wo, y_train_wo)

# Predict and evaluate
y_pred_train_wo = linear_reg_wo.predict(X_train_wo)
y_pred_test_wo = linear_reg_wo.predict(X_test_wo)

# Define the evaluate_model function to calculate evaluation metrics
def evaluate_model(y_true, y_pred, model_name):
    from sklearn.metrics import mean_squared_error, r2_score
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train_wo, y_pred_train_wo, "Linear Regression (Train) - Original")
evaluate_model(y_test_wo, y_pred_test_wo, "Linear Regression (Test) - Original")

# Calculate residuals for the training set
residuals_train_wo = y_train_wo - y_pred_train_wo

# Calculate residuals for the test set
residuals_test_wo = y_test_wo - y_pred_test_wo

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_wo, residuals_train_wo, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_wo, residuals_test_wo, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Original Residuals vs Predicted Values (Training and Test Sets)')
plt.legend()
plt.show()



"""After removing high leverage points and outliers"""

# Remove high leverage points and outliers from the dataset
data_cleaned = data_numeric.drop(index=combined_indices)

# Split the cleaned data into features and target
X_cleaned = data_cleaned[selected_features]
y_cleaned = data_cleaned[target_column]

# Add a constant term for the intercept
X_cleaned = sm.add_constant(X_cleaned)

# Split the cleaned data into training and testing sets
X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)

# Fit the model again
linear_reg_cleaned = LinearRegression()
linear_reg_cleaned.fit(X_train_cleaned, y_train_cleaned)

# Predict and evaluate
y_pred_train_cleaned = linear_reg_cleaned.predict(X_train_cleaned)
y_pred_test_cleaned = linear_reg_cleaned.predict(X_test_cleaned)

# Define the evaluate_model function to calculate evaluation metrics
def evaluate_model(y_true, y_pred, model_name):
    from sklearn.metrics import mean_squared_error, r2_score
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train_cleaned, y_pred_train_cleaned, "Linear Regression (Train) - Cleaned")
evaluate_model(y_test_cleaned, y_pred_test_cleaned, "Linear Regression (Test) - Cleaned")

# Calculate residuals for the training set
residuals_train_cleaned = y_train_cleaned - y_pred_train_cleaned

# Calculate residuals for the test set
residuals_test_cleaned = y_test_cleaned - y_pred_test_cleaned

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_cleaned, residuals_train_cleaned, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_cleaned, residuals_test_cleaned, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Cleaned Residuals vs Predicted Values (Training and Test Sets)')
plt.legend()
plt.show()

# Split the Original data into training and testing sets
X_train_wo, X_test_wo, y_train_wo, y_test_wo = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the XGBRegressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Fit the model
xgb_reg.fit(X_train, y_train)

# Predict
y_pred_train = xgb_reg.predict(X_train)
y_pred_test = xgb_reg.predict(X_test)

def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train, y_pred_train, "XGBoost Regression (Train)")
evaluate_model(y_test, y_pred_test, "XGBoost Regression (Test)")

# Calculate residuals for the training set
residuals_train = y_train - y_pred_train

# Calculate residuals for the test set
residuals_test = y_test - y_pred_test

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train, residuals_train, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test, residuals_test, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Original data XGBoost (Residuals vs Predicted Values)')
plt.legend()
plt.show()

# Initialize the XGBRegressor
xgb_reg2 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Fit the model
xgb_reg2.fit(X_train_cleaned, y_train_cleaned)

# Predict
y_pred_train_cleaned_xg = xgb_reg2.predict(X_train_cleaned)
y_pred_test_cleaned_xg = xgb_reg2.predict(X_test_cleaned)

def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train_cleaned, y_pred_train_cleaned_xg, "XGBoost Regression (Train)")
evaluate_model(y_test_cleaned, y_pred_test_cleaned_xg, "XGBoost Regression (Test)")

# Calculate residuals for the training set
residuals_train_xg = y_train_cleaned - y_pred_train_cleaned_xg

# Calculate residuals for the test set
residuals_test_xg = y_test_cleaned - y_pred_test_cleaned_xg

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_cleaned_xg, residuals_train_xg, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_cleaned_xg, residuals_test_xg, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Original data XGBoost (Residuals vs Predicted Values)')
plt.legend()
plt.show()

"""Quantile regression after feature selection"""

quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    res, y_pred_train_quant, y_pred_test_quant = quantile_regression(q, X_train_wo, y_train_wo, X_test_wo, y_test_wo)
    results[q] = (res, y_pred_train_quant, y_pred_test_quant)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_quant, y_pred_test_quant = results[q]

    # Calculate residuals for the training set
    residuals_train_quant = y_train_wo - y_pred_train_quant

    # Calculate residuals for the test set
    residuals_test_quant = y_test_wo - y_pred_test_quant

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_quant, residuals_train_quant, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_quant, residuals_test_quant, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_quant, y_pred_test_quant = results[q]

    # Calculate residuals for the training set
    residuals_train_quant = y_train_wo - y_pred_train_quant

    # Calculate residuals for the test set
    residuals_test_quant = y_test_wo - y_pred_test_quant

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_quant, residuals_train_quant, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_quant, residuals_test_quant, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""For cleaned data"""

quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    res, y_pred_train_cq, y_pred_test_cq = quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    results[q] = (res, y_pred_train_cq, y_pred_test_cq)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Calculate residuals for the training set
    residuals_train_cq = y_train_cleaned - y_pred_train_cq

    # Calculate residuals for the test set
    residuals_test_cq = y_test_cleaned - y_pred_test_cq

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_cq, residuals_train_cq, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_cq, residuals_test_cq, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Cleaned Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Calculate residuals for the training set
    residuals_train_cq = y_train_cleaned - y_pred_train_cq

    # Calculate residuals for the test set
    residuals_test_cq= y_test_cleaned - y_pred_test_cq

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_cq, residuals_train_cq, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_cq, residuals_test_cq, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""XGboost"""

# Perform XGBoost quantile regression for 0.25, 0.5, and 0.75 quantiles
quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    model, y_pred_train_quant, y_pred_test_quant = xgboost_quantile_regression(q, X_train_wo, y_train_wo, X_test_wo, y_test_wo)
    results[q] = (model, y_pred_train_quant, y_pred_test_quant)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_qxg, y_pred_test_qxg = results[q]

    # Calculate residuals for the training set
    residuals_train_qxg = y_train_wo - y_pred_train_qxg

    # Calculate residuals for the test set
    residuals_test_qxg = y_test_wo - y_pred_test_qxg

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_qxg, residuals_train_qxg, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_qxg, residuals_test_qxg, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_qxg, y_pred_test_qxg = results[q]

    # Calculate residuals for the training set
    residuals_train_qxg = y_train_wo - y_pred_train_qxg

    # Calculate residuals for the test set
    residuals_test_qxg = y_test_wo - y_pred_test_qxg

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_qxg, residuals_train_qxg, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_qxg, residuals_test_qxg, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""XGboost on clean data"""

# Perform XGBoost quantile regression for 0.25, 0.5, and 0.75 quantiles
quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    model, y_pred_train_qxgc, y_pred_test_qxgc = xgboost_quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    results[q] = (model, y_pred_train_qxgc, y_pred_test_qxgc)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_qxgc, y_pred_test_qxgc = results[q]

    # Calculate residuals for the training set
    residuals_train_qxgc = y_train_cleaned - y_pred_train_qxgc

    # Calculate residuals for the test set
    residuals_test_qxgc = y_test_cleaned - y_pred_test_qxgc

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_qxgc, residuals_train_qxgc, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_qxgc, residuals_test_qxgc, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot residuals for each quantile in separate subplots for training and testing data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

colors = ['blue', 'green', 'red']
labels = ['Quantile 0.25', 'Quantile 0.5', 'Quantile 0.75']

for i, q in enumerate(quantiles):
    res, y_pred_train_qxgc, y_pred_test_qxgc = results[q]

    # Calculate residuals for the training set
    residuals_train_qxgc = y_train_cleaned - y_pred_train_qxgc

    # Calculate residuals for the test set
    residuals_test_qxgc = y_test_cleaned - y_pred_test_qxgc

    # Plot residuals for the training set
    ax1.scatter(y_pred_train_qxgc, residuals_train_qxgc, color=colors[i], alpha=0.25, label=f'Train Residuals ({labels[i]})')

    # Plot residuals for the test set
    ax2.scatter(y_pred_test_qxgc, residuals_test_qxgc, color=colors[i], alpha=0.25, label=f'Test Residuals ({labels[i]})', marker='x')

# Customize the training residuals plot
ax1.axhline(y=0, color='black', linestyle='--')
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Residuals')
ax1.set_title('Training Residuals vs Predicted Values for Different Quantiles')
ax1.legend()

# Customize the testing residuals plot
ax2.axhline(y=0, color='black', linestyle='--')
ax2.set_xlabel('Predicted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Testing Residuals vs Predicted Values for Different Quantiles')
ax2.legend()

plt.tight_layout()
plt.show()

"""Doing same on Log prices after feature selection"""

data.head()

data_log_fs = pd.concat([data_numeric[selected_features], data[['charges', 'log_charges']]], axis=1)
data_log_fs.head()

# Assuming 'data_numeric' is your initial DataFrame and 'target_column' is defined as 'charges'
target_column = 'log_charges'
X = data_log_fs.drop(columns=[target_column, 'charges'])
y = data_log_fs[target_column]

# Add a constant term for the intercept
X = sm.add_constant(X)

# Fit the model
model = sm.OLS(y, X).fit()

# Calculate influence measures
influence = model.get_influence()

# Leverage (hat values)
leverage = influence.hat_matrix_diag

# Standardized residuals
standardized_residuals = influence.resid_studentized_internal

# Cook's distance
cooks_d = influence.cooks_distance[0]

# Identify high leverage points
high_leverage_threshold = 2 * (X.shape[1] / X.shape[0])  # Common threshold
high_leverage_points = np.where(leverage > high_leverage_threshold)[0]

# Identify outliers
outlier_threshold = 2  # Common threshold for standardized residuals
outliers = np.where(np.abs(standardized_residuals) > outlier_threshold)[0]

# Identify points with high Cook's distance
cooks_d_threshold = 4 / len(X)
high_cooks_d_points = np.where(cooks_d > cooks_d_threshold)[0]

# Combine influential points that are also high leverage points or outliers above Cook's distance threshold
combined_indices = np.unique(np.concatenate((
    np.intersect1d(high_leverage_points, high_cooks_d_points),
    np.intersect1d(outliers, high_cooks_d_points)
)))

# Plot Cook's distance
plt.figure(figsize=(10, 6))
plt.stem(np.arange(len(cooks_d)), cooks_d, markerfmt=",", linefmt='b-', basefmt=' ', label='Cook\'s Distance')

# Highlight high leverage points
plt.scatter(high_leverage_points, cooks_d[high_leverage_points], color='red', label='High Leverage Points', zorder=3)

# Highlight outliers
plt.scatter(outliers, cooks_d[outliers], color='orange', label='Outliers', zorder=3)

plt.title("Cook's Distance with High Leverage Points and Outliers")
plt.xlabel("Observation Index")
plt.ylabel("Cook's Distance")
plt.axhline(y=cooks_d_threshold, color='r', linestyle='--', label='Threshold (4/n)')
plt.legend()
plt.show()

# Display influential points summary
influential_points_summary = pd.DataFrame({
    'Index': combined_indices,
    'Leverage': leverage[combined_indices],
    'Standardized Residuals': standardized_residuals[combined_indices],
    'Cook\'s Distance': cooks_d[combined_indices]
})

# Print influential points summary
print(influential_points_summary)

"""Analysing high leverage points and outliers"""

# Extract high leverage points and outliers from the original dataset
high_leverage_outliers = data_numeric.loc[combined_indices]

# Compare high leverage points and outliers to the rest of the dataset
non_high_leverage_outliers = data_numeric.drop(index=combined_indices)

# Summary statistics for high leverage points and outliers
high_leverage_outliers_summary = high_leverage_outliers.describe()

# Summary statistics for the rest of the dataset
non_high_leverage_outliers_summary = non_high_leverage_outliers.describe()

# Display the summaries
print("Summary Statistics for High Leverage Points and Outliers:")
print(high_leverage_outliers_summary)
print("\nSummary Statistics for the Rest of the Dataset:")
print(non_high_leverage_outliers_summary)

# Visualize the high leverage points and outliers in the context of the dataset
# Pairplot can help to see the distribution and relationships between variables

# Combine the datasets with a new column to indicate if they are outliers/high leverage
high_leverage_outliers['Type'] = 'High Leverage/Outlier'
non_high_leverage_outliers['Type'] = 'Normal'

combined_data = pd.concat([high_leverage_outliers, non_high_leverage_outliers])

# Create pairplot
sns.pairplot(combined_data, hue='Type', diag_kind='kde')
plt.suptitle("Pairplot Comparing High Leverage/Outliers and Normal Points", y=1.02)
plt.show()

# Visualize distribution of each variable with boxplots
plt.figure(figsize=(15, 10))
for i, column in enumerate(data_numeric.columns):
    plt.subplot(len(data_numeric.columns) // 2 + 1, 2, i + 1)
    sns.boxplot(x='Type', y=column, data=combined_data)
    plt.title(f'Boxplot of {column}')
plt.tight_layout()
plt.show()

# Remove outliers and high leverage points above the Cook's distance threshold
data_log_fs_cleaned = data_log_fs.drop(index=combined_indices)

# reset the index of the cleaned DataFrame
data_log_fs_cleaned = data_log_fs_cleaned.reset_index(drop=True)

data_log_fs_cleaned.head()

# 'data_log_fs_cleaned' is cleaned DataFrame and 'target_column' is still 'charges'
target_column = 'log_charges'
X_cleaned = data_log_fs_cleaned.drop(columns=[target_column, 'charges'])
y_cleaned = data_log_fs_cleaned[target_column]

# Add a constant term for the intercept
X_cleaned = sm.add_constant(X_cleaned)

# Fit the model on the cleaned data
model_cleaned = sm.OLS(y_cleaned, X_cleaned).fit()

# Calculate influence measures
influence_cleaned = model_cleaned.get_influence()

# Standardized residuals for QQ plot
standardized_residuals_cleaned = influence_cleaned.resid_studentized_internal

# Cook's distance for Cook's distance plot
cooks_d_cleaned = influence_cleaned.cooks_distance[0]

# Plot QQ plot
sm.qqplot(standardized_residuals_cleaned, line='45')
plt.title("QQ Plot of Standardized Residuals (Cleaned Data)")
plt.show()

# Plot Cook's distance
plt.figure(figsize=(10, 6))
plt.stem(np.arange(len(cooks_d_cleaned)), cooks_d_cleaned, markerfmt=",", linefmt='b-', basefmt=' ', label='Cook\'s Distance')
plt.title("Cook's Distance (Cleaned Data)")
plt.xlabel("Observation Index")
plt.ylabel("Cook's Distance")
plt.axhline(y=4 / len(X_cleaned), color='r', linestyle='--', label='Threshold (4/n)')
plt.legend()
plt.show()

"""Linear Regression"""

# Add a constant term for the intercept
X_cleaned = sm.add_constant(X_cleaned)

# Split the cleaned data into training and testing sets
X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)

# Fit the model again
linear_reg_cleaned = LinearRegression()
linear_reg_cleaned.fit(X_train_cleaned, y_train_cleaned)

# Predict and evaluate
y_pred_train_cleaned = linear_reg_cleaned.predict(X_train_cleaned)
y_pred_test_cleaned = linear_reg_cleaned.predict(X_test_cleaned)

evaluate_model(y_train_cleaned, y_pred_train_cleaned, "Linear Regression (Train) - Cleaned")
evaluate_model(y_test_cleaned, y_pred_test_cleaned, "Linear Regression (Test) - Cleaned")

# Calculate residuals for the training set
residuals_train_cleaned = y_train_cleaned - y_pred_train_cleaned

# Calculate residuals for the test set
residuals_test_cleaned = y_test_cleaned - y_pred_test_cleaned

# Plot residuals for the training and test sets together
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_train_cleaned, residuals_train_cleaned, color='blue', alpha=0.25, label='Train Residuals')
plt.scatter(y_pred_test_cleaned, residuals_test_cleaned, color='red', alpha=0.25, label='Test Residuals')
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Cleaned Residuals vs Predicted Values (Training and Test Sets)')
plt.legend()
plt.show()

# Create subplots
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Plot for the training set
sns.regplot(ax=axes[0],
            x=y_train_cleaned,
            y=y_pred_train_cleaned,
            scatter_kws={'color': 'blue', 'alpha': 0.5},
            line_kws={'color': 'blue'},
            ci=95)
axes[0].plot([y_train_cleaned.min(), y_train_cleaned.max()],
             [y_train_cleaned.min(), y_train_cleaned.max()],
             '--', color='red', label='Regression Line')
axes[0].set_xlabel('Actual log Charges')
axes[0].set_ylabel('Predicted log Charges')
axes[0].set_title('Actual vs Predicted log Charges (Training Data)')
axes[0].legend()

# Plot for the test set
sns.regplot(ax=axes[1],
            x=y_test_cleaned,
            y=y_pred_test_cleaned,
            scatter_kws={'color': 'green', 'alpha': 0.5},
            line_kws={'color': 'green'},
            ci=95)
axes[1].plot([y_test_cleaned.min(), y_test_cleaned.max()],
             [y_test_cleaned.min(), y_test_cleaned.max()],
             '--', color='red', label='Regression Line')
axes[1].set_xlabel('Actual log Charges')
axes[1].set_ylabel('Predicted log Charges')
axes[1].set_title('Actual vs Predicted log Charges (Test Data)')
axes[1].legend()

# Adjust layout
plt.tight_layout()
plt.show()

# Create a combined DataFrame for easier plotting
combined_df = pd.DataFrame({
    'Actual': pd.concat([pd.Series(y_train_cleaned).reset_index(drop=True),
                         pd.Series(y_test_cleaned).reset_index(drop=True)]),
    'Predicted': pd.concat([pd.Series(y_pred_train_cleaned).reset_index(drop=True),
                            pd.Series(y_pred_test_cleaned).reset_index(drop=True)]),
    'Dataset': ['Train'] * len(y_train_cleaned) + ['Test'] * len(y_test_cleaned)
})

# Create the plot
plt.figure(figsize=(10, 6))

# Plot the training data with regression line and confidence interval
sns.regplot(data=combined_df[combined_df['Dataset'] == 'Train'],
            x='Actual',
            y='Predicted',
            scatter_kws={'color': 'blue', 'alpha': 0.5},
            line_kws={'color': 'blue'},
            label='Training Data',
            ci=95)

# Plot the test data with regression line and confidence interval
sns.regplot(data=combined_df[combined_df['Dataset'] == 'Test'],
            x='Actual',
            y='Predicted',
            scatter_kws={'color': 'green', 'alpha': 0.5},
            line_kws={'color': 'green'},
            label='Test Data',
            ci=95)

# Add a line for perfect prediction
plt.plot([combined_df['Actual'].min(), combined_df['Actual'].max()],
         [combined_df['Actual'].min(), combined_df['Actual'].max()],
         '--', color='red', label='Regression Line')

# Customize the plot
plt.xlabel('Actual Charges')
plt.ylabel('Predicted Charges')
plt.title('Actual vs Predicted log Charges (Train and Test Data)')
plt.legend()
plt.grid()
plt.show()

X_cleaned = data_log_fs_cleaned.drop(columns=[target_column, 'charges'])
y_cleaned = data_log_fs_cleaned[target_column]

# Add a constant term for the intercept
X_cleaned = sm.add_constant(X_cleaned)

# Split the cleaned data into training and testing sets
X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)

quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    res, y_pred_train_cq, y_pred_test_cq = quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    results[q] = (res, y_pred_train_cq, y_pred_test_cq)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Calculate residuals for the training set
    residuals_train_cq = y_train_cleaned - y_pred_train_cq

    # Calculate residuals for the test set
    residuals_test_cq = y_test_cleaned - y_pred_test_cq

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_cq, residuals_train_cq, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_cq, residuals_test_cq, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Cleaned Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()

# Create subplots for each quantile
fig, axes = plt.subplots(1, len(quantiles), figsize=(18, 6))

for i, q in enumerate(quantiles):
    # Unpack the results
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Create a combined DataFrame for easier plotting
    combined_df = pd.DataFrame({
        'Actual': pd.concat([y_train_cleaned.reset_index(drop=True), y_test_cleaned.reset_index(drop=True)]),
        'Predicted': pd.concat([pd.Series(y_pred_train_cq).reset_index(drop=True),
                                pd.Series(y_pred_test_cq).reset_index(drop=True)]),
        'Dataset': ['Train'] * len(y_train_cleaned) + ['Test'] * len(y_test_cleaned)
    })

    # Plot for the current quantile
    sns.regplot(ax=axes[i],
                data=combined_df,
                x='Actual',
                y='Predicted',
                scatter_kws={'alpha': 0.5},
                line_kws={'color': 'blue'},
                ci=None)

    # Add a line for perfect prediction
    axes[i].plot([combined_df['Actual'].min(), combined_df['Actual'].max()],
                  [combined_df['Actual'].min(), combined_df['Actual'].max()],
                  '--', color='red', label='Perfect Prediction Line')

    # Customize the plot
    axes[i].set_title(f'Actual vs Predicted Charges (Quantile: {q})')
    axes[i].set_xlabel('Actual Charges')
    axes[i].set_ylabel('Predicted Charges')
    axes[i].legend()

# Adjust layout
plt.tight_layout()
plt.show()

# Create subplots: 1 row, 2 columns
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Linear Regression Plot
# Combine actual and predicted values for linear regression
actual_linear = pd.concat([y_train_cleaned, y_test_cleaned]).reset_index(drop=True)
predicted_linear = pd.concat([pd.Series(y_pred_train_cleaned), pd.Series(y_pred_test_cleaned)]).reset_index(drop=True)

sns.regplot(ax=axes[0],
            x=actual_linear,
            y=predicted_linear,
            scatter_kws={'color': 'blue', 'alpha': 0.5},
            line_kws={'color': 'blue'},
            ci=None)
axes[0].plot([actual_linear.min(), actual_linear.max()],
              [actual_linear.min(), actual_linear.max()],
              '--', color='red', label='Perfect Prediction Line')
axes[0].set_xlabel('Actual Charges')
axes[0].set_ylabel('Predicted Charges')
axes[0].set_title('Linear Regression: Actual vs Predicted Charges')
axes[0].legend()

# Quantile Regression Plot for 0.5 Quantile
q = 0.5
res, y_pred_train_cq, y_pred_test_cq = results[q]

# Create a combined DataFrame for the quantile regression plot
combined_df_q5 = pd.DataFrame({
    'Actual': pd.concat([y_train_cleaned.reset_index(drop=True), y_test_cleaned.reset_index(drop=True)]),
    'Predicted': pd.concat([pd.Series(y_pred_train_cq).reset_index(drop=True),
                            pd.Series(y_pred_test_cq).reset_index(drop=True)]),
    'Dataset': ['Train'] * len(y_train_cleaned) + ['Test'] * len(y_test_cleaned)
})

sns.regplot(ax=axes[1],
            data=combined_df_q5,
            x='Actual',
            y='Predicted',
            scatter_kws={'color': 'green', 'alpha': 0.5},
            line_kws={'color': 'green'},
            ci=None)
axes[1].plot([combined_df_q5['Actual'].min(), combined_df_q5['Actual'].max()],
              [combined_df_q5['Actual'].min(), combined_df_q5['Actual'].max()],
              '--', color='red', label='Regression Line')
axes[1].set_xlabel('Actual Charges')
axes[1].set_ylabel('Predicted Charges')
axes[1].set_title('Quantile Regression (0.5): Actual vs Predicted Charges')
axes[1].legend()

# Adjust layout
plt.tight_layout()
plt.show()

"""XG Boost

Linear Regression
"""

# Split the Original data into training and testing sets
X_train_wo, X_test_wo, y_train_wo, y_test_wo = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the XGBRegressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Fit the model
xgb_reg.fit(X_train, y_train)

# Predict
y_pred_train = xgb_reg.predict(X_train)
y_pred_test = xgb_reg.predict(X_test)

def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f'{model_name} - Mean Squared Error: {mse:.4f}, R2 Score: {r2:.4f}')

evaluate_model(y_train, y_pred_train, "XGBoost Regression (Train)")
evaluate_model(y_test, y_pred_test, "XGBoost Regression (Test)")

X_cleaned = data_log_fs_cleaned.drop(columns=[target_column, 'charges'])
y_cleaned = data_log_fs_cleaned[target_column]

# Add a constant term for the intercept
X_cleaned = sm.add_constant(X_cleaned)

# Split the cleaned data into training and testing sets
X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)

quantiles = [0.25, 0.5, 0.75]
results = {}

for q in quantiles:
    #res, y_pred_train_cq, y_pred_test_cq = quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    res, y_pred_train_cq, y_pred_test_cq = xgboost_quantile_regression(q, X_train_cleaned, y_train_cleaned, X_test_cleaned, y_test_cleaned)
    results[q] = (res, y_pred_train_cq, y_pred_test_cq)

plt.figure(figsize=(15, 10))

for i, q in enumerate(quantiles):
    res, y_pred_train_cq, y_pred_test_cq = results[q]

    # Calculate residuals for the training set
    residuals_train_cq = y_train_cleaned - y_pred_train_cq

    # Calculate residuals for the test set
    residuals_test_cq = y_test_cleaned - y_pred_test_cq

    # Plot residuals for the training and test sets together
    plt.subplot(2, 2, i+1)
    plt.scatter(y_pred_train_cq, residuals_train_cq, color='blue', alpha=0.25, label='Train Residuals')
    plt.scatter(y_pred_test_cq, residuals_test_cq, color='red', alpha=0.25, label='Test Residuals')
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title(f'Cleaned Residuals vs Predicted Values (Quantile {q})')
    plt.legend()

plt.tight_layout()
plt.show()